{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries\n",
    "Import libraries such as torch, torch.nn, torch.optim, spacy, and pyvi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import spacy\n",
    "from pyvi import ViTokenizer\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Prepare the Dataset\n",
    "Download and load the IWSLT 2015 TED Talks dataset for Vietnamese-English translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "tar: Error opening archive: Failed to open 'vi-en.tgz'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'iwslt-vi-en/train.vi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[0;32m      8\u001b[0m vi_en_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miwslt-vi-en/train.vi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m vi_file, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miwslt-vi-en/train.en\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m en_file:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m vi_line, en_line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(vi_file, en_file):\n\u001b[0;32m     11\u001b[0m         vi_en_data\u001b[38;5;241m.\u001b[39mappend((vi_line\u001b[38;5;241m.\u001b[39mstrip(), en_line\u001b[38;5;241m.\u001b[39mstrip()))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'iwslt-vi-en/train.vi'"
     ]
    }
   ],
   "source": [
    "# Load and Prepare the Dataset\n",
    "\n",
    "# Download the dataset from IWSLT 2015 TED Talks\n",
    "!wget https://wit3.fbk.eu/archive/2015-01/texts/vi/en/vi-en.tgz\n",
    "!tar -xvzf vi-en.tgz\n",
    "\n",
    "# Load the dataset\n",
    "vi_en_data = []\n",
    "with open('iwslt-vi-en/train.vi', 'r', encoding='utf-8') as vi_file, open('iwslt-vi-en/train.en', 'r', encoding='utf-8') as en_file:\n",
    "    for vi_line, en_line in zip(vi_file, en_file):\n",
    "        vi_en_data.append((vi_line.strip(), en_line.strip()))\n",
    "\n",
    "print(f'Total number of sentence pairs: {len(vi_en_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization and Tokenization\n",
    "Normalize and tokenize the text using spacy for English and pyvi for Vietnamese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load language models\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "def tokenize_vi(text):\n",
    "    return ViTokenizer.tokenize(text).split()\n",
    "\n",
    "# Example of tokenization\n",
    "print('English:', tokenize_en('This is a test sentence.'))\n",
    "print('Vietnamese:', tokenize_vi('Đây là một câu kiểm tra.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation\n",
    "Split the dataset into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "random.shuffle(vi_en_data)\n",
    "\n",
    "train_data = vi_en_data[:int(0.8*len(vi_en_data))]\n",
    "valid_data = vi_en_data[int(0.8*len(vi_en_data)):int(0.9*len(vi_en_data))]\n",
    "test_data = vi_en_data[int(0.9*len(vi_en_data)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary\n",
    "Create vocabulary for both languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(tokenizer, data, min_freq):\n",
    "    counter = Counter()\n",
    "    for sentence in data:\n",
    "        tokens = tokenizer(sentence)\n",
    "        counter.update(tokens)\n",
    "    return {word: idx for idx, (word, freq) in enumerate(counter.items()) if freq >= min_freq}\n",
    "\n",
    "SRC_VOCAB = build_vocab(tokenize_vi, [sentence[0] for sentence in train_data], min_freq=2)\n",
    "TRG_VOCAB = build_vocab(tokenize_en, [sentence[1] for sentence in train_data], min_freq=2)\n",
    "\n",
    "print(f'Size of Vietnamese vocabulary: {len(SRC_VOCAB)}')\n",
    "print(f'Size of English vocabulary: {len(TRG_VOCAB)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader\n",
    "Create DataLoader objects for the training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data, src_vocab, trg_vocab, src_tokenizer, trg_tokenizer):\n",
    "        self.data = data\n",
    "        self.src_vocab = src_vocab\n",
    "        self.trg_vocab = trg_vocab\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.trg_tokenizer = trg_tokenizer\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        src_sentence, trg_sentence = self.data[idx]\n",
    "        src_tokens = [self.src_vocab.get(token, 0) for token in self.src_tokenizer(src_sentence)]\n",
    "        trg_tokens = [self.trg_vocab.get(token, 0) for token in self.trg_tokenizer(trg_sentence)]\n",
    "        return torch.tensor(src_tokens), torch.tensor(trg_tokens)\n",
    "\n",
    "train_dataset = TranslationDataset(train_data, SRC_VOCAB, TRG_VOCAB, tokenize_vi, tokenize_en)\n",
    "valid_dataset = TranslationDataset(valid_data, SRC_VOCAB, TRG_VOCAB, tokenize_vi, tokenize_en)\n",
    "test_dataset = TranslationDataset(test_data, SRC_VOCAB, TRG_VOCAB, tokenize_vi, tokenize_en)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=lambda x: x)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, collate_fn=lambda x: x)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the LSTM Model\n",
    "Define the LSTM model for sequence-to-sequence translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        return prediction, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        trg_len = trg.shape[0]\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        hidden, cell = self.encoder(src)\n",
    "        input = trg[0,:]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            top1 = output.argmax(1) \n",
    "            input = trg[t] if random.random() < teacher_forcing_ratio else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "Train the Seq2Seq model using the prepared dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "\n",
    "INPUT_DIM = len(SRC_VOCAB)\n",
    "OUTPUT_DIM = len(TRG_VOCAB)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "TRG_PAD_IDX = TRG_VOCAB['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(iterator):\n",
    "        src, trg = zip(*batch)\n",
    "        src = nn.utils.rnn.pad_sequence(src, padding_value=SRC_VOCAB['<pad>']).to(device)\n",
    "        trg = nn.utils.rnn.pad_sequence(trg, padding_value=TRG_VOCAB['<pad>']).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            src, trg = zip(*batch)\n",
    "            src = nn.utils.rnn.pad_sequence(src, padding_value=SRC_VOCAB['<pad>']).to(device)\n",
    "            trg = nn.utils.rnn.pad_sequence(trg, padding_value=TRG_VOCAB['<pad>']).to(device)\n",
    "            output = model(src, trg, 0)\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion)\n",
    "    print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model\n",
    "Test the model on the test set and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the Model\n",
    "\n",
    "test_loss = evaluate(model, test_loader, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
